{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ki1UnQSgUhRN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv \n",
        "import json\n",
        "import math\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter\n",
        "from datetime import datetime as DT\n",
        "from datetime import timezone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initialize the path variables of your own piazza dataset\n",
        "COURSE = \"sample_course\"\n",
        "SEMESTER = \"sample_semester\"\n",
        "semesters = {\"sample_course\": [\"sample_semester\"]}\n",
        "\n",
        "def set_paths(course=COURSE, semester=SEMESTER):\n",
        "    BASE = f'{course}_data/'\n",
        "    PATH = f\"{course}_data/Piazza_Data/Piazza_{semester}/\"\n",
        "    IMG_PATH = f\"{course}_data/Processed_Data/Piazza_{semester}/images/\"\n",
        "    PROC_PATH = f\"{course}_data/Processed_Data/Piazza_{semester}/\"\n",
        "        # Create directories if they don't exist\n",
        "    if not os.path.exists(IMG_PATH):\n",
        "        os.makedirs(IMG_PATH)\n",
        "    return BASE, PATH, IMG_PATH, PROC_PATH\n",
        "\n",
        "BASE, PATH, IMG_PATH, PROC_PATH = set_paths()\n",
        "\n",
        "def get_part_csv(course=COURSE, part='QA', path=BASE):\n",
        "    return f'{path}{course}_{part}_nofollowup_preOCR.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aleLjSIhTe_0",
        "outputId": "c36c7084-68ba-4ef2-9c9d-b434f9eb30f2"
      },
      "outputs": [],
      "source": [
        "def write_to_json(directory, file_name, json_obj_lst):\n",
        "    p = Path(directory)\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "    file = f\"{directory}/{file_name}\"\n",
        "    if not os.path.exists(file):  # create file not exist and write empty list\n",
        "        with open(file, 'w+') as f:\n",
        "            json.dump([], f)\n",
        "    with open(file) as f:\n",
        "        json_list = json.load(f)\n",
        "        json_list += json_obj_lst\n",
        "\n",
        "    with open(file, 'w') as f:\n",
        "        json.dump(json_list, f, separators=(',', ': '), indent=4)\n",
        "    return\n",
        "\n",
        "def to_json(data):\n",
        "    if data is None or isinstance(data, (bool, int, str)): return data\n",
        "    if isinstance(data, np.integer):\n",
        "        return int(data)\n",
        "    if isinstance(data, list):\n",
        "        return [to_json(v) for v in data]\n",
        "    if isinstance(data, dict):\n",
        "        return {to_json(key): to_json(value) for key, value in data.items()}\n",
        "    else:\n",
        "        print(\"other type\", type(data), data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# zulutime = \"2021-08-31T20:06:32.011Z\", 2019-07-09T05:46:25.557Z\n",
        "def zulu_to_utc(zulutime):\n",
        "    dt = DT.fromisoformat(zulutime.replace('Z', '+00:00'))\n",
        "    # utctime => \"2021-08-31 20:06:32 UTC\"\n",
        "    return dt.strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n",
        "\n",
        "def zulu_near_utc(zulutime):\n",
        "    # return utc0, utc1, utc2 that's one second before, at, and after zulutime\n",
        "    dt = DT.fromisoformat(zulutime.replace('Z', '+00:00'))\n",
        "    utc_format = \"%Y-%m-%d %H:%M:%S UTC\"\n",
        "    utc1 = dt.strftime(utc_format)\n",
        "    utc2 = (dt + pd.Timedelta(seconds=1)).strftime(utc_format)\n",
        "    utc0 = (dt - pd.Timedelta(seconds=1)).strftime(utc_format)\n",
        "    return utc0, utc1, utc2\n",
        "\n",
        "# define is_close function to check if two timestamps are close enough\n",
        "def is_close(dt1, dt2):\n",
        "    diff = dt1 - dt2\n",
        "    return abs(diff.total_seconds()) < 1\n",
        "\n",
        "# zulu = \"2015-10-20T00:15:52.992Z\" is_close utc = \"2015-10-20 00:15:53 UTC\"\n",
        "def zulu_vs_utc(zulutime, utc):\n",
        "    dt_zulu = DT.fromisoformat(zulutime.replace('Z', '+00:00'))\n",
        "    # print(dt.utcfromtimestamp(dt.timestamp()))\n",
        "    dt_utc = DT.strptime(utc, '%Y-%m-%d %H:%M:%S %Z').replace(tzinfo=timezone.utc)\n",
        "    # Note Excluded time components are truncated, not rounded.\n",
        "    return is_close(dt_zulu, dt_utc)\n",
        "\n",
        "def find_match_time(zulu, row):\n",
        "    return zulu_vs_utc(zulu, row['Created At'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: there are href tags in the html that isn't processed yet\n",
        "# with .png or .jpg as the ending of href, e.g., url = f\"https://piazza.com/{a.get('href')}\"\n",
        "# there can be <md> tags and images in markdown too, <a href in markdown2.markdown(tag.text))\n",
        "def str_html(html):\n",
        "    # turn br tag into \\n\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    for br in soup.find_all(\"br\"): #[\"br\", \"md\"] print(\"adding br.text?\", br.text)\n",
        "        br.replace_with(\"\\n\" + br.text)\n",
        "    return soup.get_text() \n",
        "\n",
        "def request_html(url):\n",
        "    try:\n",
        "        r = requests.get(url, timeout=10)\n",
        "    except Exception as e:\n",
        "        # print(\"Exception occur while requesting\", e)\n",
        "        return False, None\n",
        "    if r.status_code != 200: \n",
        "        print(\"Error requesting\", r.status_code, url, r.content)\n",
        "        return False, None\n",
        "    return True, r.content\n",
        "\n",
        "def extract_img_from_html(html_text, postid, post_part, postnum, semester, course=COURSE, IMG_PATH=IMG_PATH):\n",
        "    # output img file already with ID, src_url (unique key), url, postid, idx, and then ocr\n",
        "    soup = BeautifulSoup(html_text, 'html.parser')\n",
        "    images = []\n",
        "    # IMG_PATH = f\"{course}_data/Processed_Data/Piazza_{semester}/images/\"\n",
        "    for (index, img) in enumerate(soup.find_all('img')):\n",
        "        src_url = img.get('src')\n",
        "        url = src_url\n",
        "        success_src, content = request_html(src_url)\n",
        "        if not success_src:\n",
        "            url = f\"https://piazza.com{src_url}\"\n",
        "            success, content = request_html(url)\n",
        "            if not success:\n",
        "                print(\"neither urls worked\", src_url, url)\n",
        "                continue\n",
        "\n",
        "        img_name = f\"{postid}_{index}.png\"\n",
        "        # print(postnum, img_name, len(content), post_part)\n",
        "        with open(f\"{IMG_PATH}{img_name}\", 'wb') as f:\n",
        "            f.write(content)\n",
        "        images.append({\"img_id\": img_name, \"semester\": semester, \"postnum\": postnum, \"post_part\": post_part, \"src_url\": src_url, \"success_url\": url, \"ocr_text\": None, \"ocr_valid\": None})\n",
        "    return images\n",
        "\n",
        "# TODO if ocr=True, read from images.json in IMG_PATH\n",
        "def process_html_text(html_text, postid, ocr=False, IMG_PATH=None):\n",
        "    if not ocr: return str_html(html_text)\n",
        "    # with the postid, find the images urls and the ocr_text\n",
        "    # then match src_url with html_text using soup.find_all('img', {'src': src_url}) and replace with <pre>ocr_text</pre>\n",
        "    # return the str_html of new html_text"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Read headers & first entry of different files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hNrbDz4RT-yx"
      },
      "outputs": [],
      "source": [
        "# \"class_content_flat.json\"\n",
        "def get_class_content_flat(path):\n",
        "    with open(f\"{path}/class_content_flat.json\") as f:\n",
        "        class_content_flat = json.load(f)\n",
        "    print(\"class_content_flat.json\", len(class_content_flat))\n",
        "    return class_content_flat\n",
        "\n",
        "# \"contributions.csv\"\n",
        "def get_contributions(path):\n",
        "    with open(f\"{path}/contributions.csv\") as f:\n",
        "        contributions = pd.read_csv(f)\n",
        "    print(path, \"contributions.csv\", len(contributions))\n",
        "    labels = set()\n",
        "    for folders in set(contributions[\"Folders\"]):\n",
        "        if type(folders) != str: \n",
        "            print(folders) # folders can also be nan\n",
        "            continue\n",
        "        labels.update(folders.split(\"; \"))\n",
        "    print(\"Folders\", len(labels), labels)\n",
        "    return contributions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Anonymize data & remove identifiable info\n",
        "Note that if your dataset is not pre-anonymized, consider remove at least these fields & replace with anonymize user_id. Although the dataset we used is already anonymized, some reference code is provided for your convenience. \n",
        "\n",
        "Note that we can also infer teh roles of student vs. instructors (those who answered questions)\n",
        "- `users.json`\n",
        "  - 'name': \n",
        "  - 'email': \n",
        "  - 'lti_ids': []\n",
        "- `contributionw.csv`\n",
        "  - Name\tEmail -> replace with user_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# proxy to instructor: who answered question \n",
        "def get_proxy_to_instructor(class_content_flat):\n",
        "    instructors = set()\n",
        "    for post in class_content_flat:\n",
        "        if post[\"type\"] == \"i_answer\":\n",
        "            instructors.update(post[\"editors\"])\n",
        "    return instructors\n",
        "\n",
        "# after added the role inference, return a set of instructors from users.json \"role\" == \"instructor\"\n",
        "def get_instructors():\n",
        "    with open(f\"{PATH}users.json\", 'r') as f:\n",
        "        users = json.load(f)\n",
        "        instructors = set([user[\"user_id\"] for user in users if user[\"role\"] == \"instructor\"])\n",
        "    print(\"instructors\", len(instructors), instructors)\n",
        "    return instructors\n",
        "\n",
        "def remove_config(path):\n",
        "    # remove file \"config.json\" from PATH\n",
        "    if os.path.exists(f\"{path}/config.json\"):\n",
        "        os.remove(f\"{path}/config.json\")\n",
        "\n",
        "def anonymize_users(instructors, path, proc_path):\n",
        "    name_to_id, email_to_id = {}, {\"Not currently enrolled\": \"NotEnrolled\", \"Anon\": \"Anonymous\"}\n",
        "    print(\"# instructors: \", len(instructors)) \n",
        "    if os.path.exists(f\"{path}/users.json\"):\n",
        "        with open(f\"{path}/users.json\") as f:\n",
        "            users = json.load(f)\n",
        "            print(\"# Piazza users in total:\", len(users))\n",
        "            anonymized_users = []\n",
        "            for user in users:\n",
        "                email_to_id[user[\"email\"]] = user[\"user_id\"]\n",
        "                name_to_id[user[\"name\"]] = user[\"user_id\"]\n",
        "                user[\"role\"] = 'instructor' if user[\"user_id\"] in instructors else 'student'\n",
        "                anonymized_user = {\"user_id\": user[\"user_id\"], \"role\": user[\"role\"], \"days\": user[\"days\"], \"posts\": user[\"posts\"], \"asks\": user[\"asks\"], \"answers\": user[\"answers\"], \"views\": user[\"views\"]}\n",
        "                anonymized_users.append(anonymized_user)\n",
        "        return anonymized_users, name_to_id, email_to_id\n",
        "\n",
        "# replace the Name and Email column of contributions.csv with user_id\n",
        "def replace_name_email_with_id(contributions, email_to_id):\n",
        "    if \"Email\" not in contributions.columns and \"UserID\" in contributions.columns: return contributions\n",
        "    contributions[\"UserID\"] = contributions[\"Email\"].apply(lambda x: email_to_id[x])\n",
        "    # select a subset of columns to write to file\n",
        "    contributions = contributions[['Anonymous', 'Post Number', 'Folders', 'Created At', 'Submission', 'Submission HTML Removed', 'Subject', 'Part of Post', 'Endorsed by Instructor', 'UserID']]\n",
        "    return contributions\n",
        "\n",
        "def anonymize_all_semesters(sem_list, course=COURSE):\n",
        "    # for course, sems in semesters.items():\n",
        "    for sem in sem_list:\n",
        "        PATH, IMG_PATH, PROC_PATH = set_paths(course, sem)\n",
        "\n",
        "        remove_config(PATH)\n",
        "        contributions = get_contributions(PATH)\n",
        "        class_content_flat = get_class_content_flat(PATH)\n",
        "        instructors = get_proxy_to_instructor(class_content_flat)\n",
        "        anonymized_users, name_to_id, email_to_id = anonymize_users(instructors, PATH, PROC_PATH)\n",
        "        contributions = replace_name_email_with_id(contributions, email_to_id)\n",
        "\n",
        "        # re-write\n",
        "        with open(f\"{PATH}/users.json\", 'w') as f: json.dump(anonymized_users, f, indent=4)\n",
        "        # don't save these mappings for the final anonymized dataset\n",
        "        # with open(f\"{PROC_PATH}/name_to_id.json\", 'w') as f: json.dump(name_to_id, f, indent=4)\n",
        "        # with open(f\"{PROC_PATH}/email_to_id.json\", 'w') as f: json.dump(email_to_id, f, indent=4)\n",
        "        contributions.to_csv(f\"{PATH}/contributions.csv\", index=False)\n",
        "\n",
        "# uncomment this line if your dataset is not anonymized yet\n",
        "# anonymize_all_semesters([SEMESTER])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Match class_content_flat.json (final posts) with contributions.csv\n",
        "- ## class_content_flat.json: the finalized post\n",
        "\t- `'id'`\n",
        "\t- `'type'`:\t\t'note', 'question',' i_answer', 's_answer', 'followup', followup_response'\n",
        "\t- `'created'`: \tZulu time\n",
        "\t- `'subject'`:\tcome with the question or note type\n",
        "\t- `'content'`:\tHTML text, can be matched with Submission after .strip() and taken account of '' cases\n",
        "\t- `'parent_id'`:\tparent thread id, a followup's parent is the original post, a followup_response's parent is the followup, multiple followup_response to the same followup share the same parent_id\n",
        "\t- `'thread_id'`:\toriginal post id, the thread's root, a followup & followup_response's thread is the original post\n",
        "\t- `'views'`\n",
        "\t- `'editors'`:\tlist of user_id\n",
        "\t- `'score'`:\t\tlen(tag_good_arr), # people liked this post\n",
        "\t- `'tag_good_arr'`\n",
        "\t- `'anonimity'`\n",
        "\n",
        "- ## contributions.csv: all edit history of post\n",
        " \t* `Anonymous`,\n",
        "\t* `Post Number`:\t@piazza post num for reference\n",
        "\t* `Folders`:\t\tlist of labels/folders that the post has been bucketed into on piazza, e.g., \n",
        "\t\t\t\t\t'exercises', 'hw1', 'hw4', 'hw3', 'hw6', 'hw2', 'quiz5', 'quiz4', 'quiz3', 'hw5', 'other', 'logistics', 'lecture', 'quiz2', 'final', 'quiz1'\n",
        "\t* `Created At`:\tUTC time\n",
        "\t* `Submission`:\tHTML text, can be NaN with pd\n",
        "\t* `Submission HTML Removed`,\n",
        "\t* `Subject`,\n",
        "\t* `Part of Post`: 'followup', 'reply_to_followup', \n",
        "\t\t\t\t\t'started_off_i_answer', 'started_off_note', 'started_off_poll',\n",
        "\t\t\t\t\t'started_off_question', 'started_off_s_answer', 'updated_i_answer', 'updated_note', 'updated_question', 'updated_s_answer'\n",
        "\t* `Endorsed by Instructor`: True, False, NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def nan_to_false(endorsed):\n",
        "    if isinstance(endorsed, bool): return endorsed \n",
        "    else: return False # T/F, make NaN to F too\n",
        "\n",
        "def get_additional_fields(match):\n",
        "    postnum = match['Post Number'].values[0] # the post number\n",
        "    folders = match['Folders'].values[0] # the folders list\n",
        "    endorsed = match['Endorsed by Instructor'].values[0] # the endorsed label\n",
        "    utc = match['Created At'].values[0] # use the utc time of the updated content\n",
        "    # edit = match['Part of Post'].values[0] # the edit label, e.g., 'started_off_s_answer', 'updated_i_answer', 'started_off_i_answer', 'updated_s_answer'\n",
        "    return utc, postnum, folders, nan_to_false(endorsed)\n",
        "\n",
        "def check_match_content(final_content, contributions, postnum=None):\n",
        "    match_content = contributions[contributions[\"Submission\"] == final_content]\n",
        "    if postnum != None:\n",
        "        match_content = match_content[match_content[\"Post Number\"] == postnum]\n",
        "    if len(match_content) == 1: # there's a match in content\n",
        "        return get_additional_fields(match_content)\n",
        "    elif len(match_content) > 1: # there's more than one match in content, probably update something else\n",
        "        # choose the one with later Created At field, but also matching postnum\n",
        "        match_content = match_content.sort_values(by=['Created At'], ascending=False)\n",
        "        return get_additional_fields(match_content)\n",
        "    # else: print(\"no match in content\") \n",
        "\n",
        "def get_updated_answer(post_type, post_part, post_threads, postid, post_content, updated_ans, match_time, role='i'):\n",
        "    assert(post_type == f\"{role}_answer\")\n",
        "    if post_part == f'updated_{role}_answer':\n",
        "        started_off_answer = post_threads[post_threads[\"Part of Post\"] == f'started_off_{role}_answer']\n",
        "        assert len(started_off_answer) == 1, f\"len(started_off_s/i_answer) = {len(started_off_answer)} != 1\"\n",
        "        return process_html_text(started_off_answer[\"Submission\"].values[0], postid, ocr=False)\n",
        "    else:\n",
        "        assert(post_part == f'started_off_{role}_answer')\n",
        "        updated_answer = post_threads[post_threads[\"Part of Post\"] == f'updated_{role}_answer']\n",
        "\n",
        "        if len(post_threads[post_threads[\"Part of Post\"] == f'updated_{role}_answer']) != 0:\n",
        "            print(\"postid\", postid, post_type, post_part, role)\n",
        "            print(\"post_content\", post_content)\n",
        "            print(\"updated_ans_clean_content\", updated_ans)\n",
        "            print(\"updated_answer\", updated_answer)\n",
        "            print(\"match_time\", match_time)\n",
        "            print(\"post_threads\", post_threads)\n",
        "            assert False, f\"len(updated_{role}_answer) != 0\"\n",
        "\n",
        "def all_edit_history_same(match_content):\n",
        "    # not necessarily len=2 match_content[\"Submission\"].values[0] == [1] + .strip())\n",
        "    contents = set(match_content[\"Submission\"].values)\n",
        "    stripped_contents = set([content.strip() for content in match_content[\"Submission\"].values])\n",
        "    return len(contents) == 1 or len(stripped_contents) == 1 # all edits are the same\n",
        "\n",
        "\n",
        "def find_updated(match_time, postnum, postid, post_type, post_content, updated_ans, contributions):\n",
        "    post_threads = contributions[contributions[\"Post Number\"] == postnum]\n",
        "    answers_part = ['started_off_i_answer', 'updated_i_answer', 'started_off_s_answer', 'updated_s_answer']\n",
        "    match_content = post_threads.loc[((post_threads[\"Submission\"] == post_content) | (post_threads[\"Submission\"] == post_content.strip())) & \n",
        "                                     (post_threads[\"Part of Post\"].isin(answers_part))]\n",
        "    # after filter part of post == answer, it's possible that content literally didn't change among edits\n",
        "    if len(match_content) > 1: # since filter used strip, possible edits like \\n\\n, so compare both strip too\n",
        "        assert all_edit_history_same(match_content), \\\n",
        "                f\"len(match_content) = {len(match_content)}, {match_content['Submission'].values}\"\n",
        "        # manually only keep the started_off_{}_answer in that case\n",
        "        return {\"updated_answer\": None, \"started_off_answer\": updated_ans}\n",
        "    elif len(match_content) == 0:\n",
        "        print(\"match_time post, why would there be mismatched postnum?\", match_time)\n",
        "        print(\"post_threads\", post_threads)\n",
        "        print(\"postid\", postid, \"postnum\", postnum, post_type)\n",
        "        print(\"post_content\", post_content, \"updated_ans:\", updated_ans)\n",
        "        assert False, \"len(match_content) == 0\"\n",
        "    \n",
        "    assert len(match_content) == 1, f\"len(match_content) = {len(match_content)}, match_content = {match_content['Submission'].values}\"\n",
        "    post_part = match_content[\"Part of Post\"].values[0]\n",
        "    role = post_part.split('_')[-2]\n",
        "    assert role in ['s', 'i']\n",
        "    init_ans = get_updated_answer(post_type, post_part, post_threads, postid, post_content, updated_ans, match_time, role)\n",
        "    if init_ans == None: # print(\"no edits existed\")\n",
        "        return {\"updated_answer\": None, \"started_off_answer\": updated_ans}\n",
        "    else:\n",
        "        return {\"updated_answer\": updated_ans, \"started_off_answer\": init_ans}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# make a dictionary with key being postnum\n",
        "# value being class_content_flat with additional fields from contributions.csv\n",
        "def get_all_posts(class_content_flat, contributions):\n",
        "    all_posts = {}\n",
        "    for post in class_content_flat:\n",
        "        if post['type'] == 'poll': continue # skip poll\n",
        "        final_content = post['content'].strip() if isinstance(post['content'], str) else \"\"\n",
        "        # cutomize & parse img links & ocr\n",
        "        clean_content = process_html_text(final_content, post['id'], ocr=False)\n",
        "        # find the row in contributions that has value at 'Created At' column == utctime\n",
        "        # utc = zulu_to_utc(post[\"created\"])\n",
        "        utc0, utc1, utc2 = zulu_near_utc(post[\"created\"])\n",
        "        match_time = contributions[ (contributions[\"Created At\"] == utc0) | \n",
        "                                    (contributions[\"Created At\"] == utc1) | (contributions[\"Created At\"] == utc2) ]\n",
        "        # match_time = contributions[contributions.apply(lambda row: find_match_time(post[\"created\"], row), axis=1)]\n",
        "        if len(match_time) == 1: # there's a match in timestamp (started off time, not edited time)\n",
        "            # the timestamp is the started off time, not the edited time, so content may be different\n",
        "            utc, postnum, folders, endorsed = get_additional_fields(match_time)\n",
        "            # extract the string content in match['Submission'] and compare with post[\"content\"]\n",
        "            same_time_content = match_time['Submission'].values[0]\n",
        "            if final_content == \"\":\n",
        "                if isinstance(same_time_content, str): # the content is deleted\n",
        "                    print(\"Deleted/Resolved empty post, ignore it\", match_time.values)\n",
        "                    continue\n",
        "                else:\n",
        "                    assert(math.isnan(same_time_content)) # empty post match, question in subject\n",
        "                    print(postnum, \"empty post match, question in subject\")\n",
        "\n",
        "            elif (isinstance(same_time_content, str) and same_time_content.strip() != final_content):\n",
        "                # and str_html(final_content) != match_time['Submission HTML Removed'].values[0].strip()): # the content is edited\n",
        "                # html or html_removed version is the same? \n",
        "                # updated post? but updated content may be empty, so postnum can be matched to a wrong one \n",
        "                result = check_match_content(post['content'], contributions, postnum)\n",
        "                if result == None: \n",
        "                    print(\"Can be possible if student not currently enrolled, ignore\")\n",
        "                    # print(post, match_time.values)\n",
        "                    continue\n",
        "                else: utc, postnum, folders, endorsed = result\n",
        "            # else: pass # perfect match\n",
        "        \n",
        "        else: # TODO, only use content to check match may still be buggy, postnum may be wrong\n",
        "            if len(match_time.values) > 1: # multiple same timestamp match\n",
        "                result = check_match_content(post['content'], contributions)\n",
        "                if result == None: \n",
        "                    print(\"\\nNo content match, is empty/duplicate content? \", len(post['content'])==0, \n",
        "                          len(match_time.values), \"posts same time\", match_time.values)\n",
        "                    continue\n",
        "                else: utc, postnum, folders, endorsed = result\n",
        "\n",
        "            else: # there's no match in timestamp for class_content_flat.json & contributions.csv\n",
        "                assert len(match_time.values) == 0, f\"No match in time? len(match_time.values) = {len(match_time.values)}\"\n",
        "                result = check_match_content(post['content'], contributions)\n",
        "                if result == None: continue\n",
        "                else: utc, postnum, folders, endorsed = result\n",
        "                print(\"No match in time but found match content\", postnum, post['id'], utc, postnum)\n",
        "                # print('post[\"created\"]->utc', post[\"created\"], zulu_to_utc(post[\"created\"]))\n",
        "                # print(\"rematched using content\", utc, type(utc))\n",
        "\n",
        "        addition = {\"utc\": utc, \"postnum\": postnum, \"folders\": folders, \"endorsed\": endorsed, \"clean_content\": clean_content}\n",
        "        # find edited post, started_off_s_answer, updated_i_answer, started_off_i_answer, updated_s_answer\n",
        "        if post['type'] in ['i_answer', 's_answer']: \n",
        "            answer_edit = find_updated(match_time, postnum, post['id'], post['type'], post['content'], clean_content, contributions)\n",
        "            addition['answer_edit'] = answer_edit\n",
        "        post.update(addition)\n",
        "        # add to all_posts and setdefault = [], if exist append\n",
        "        all_posts.setdefault(postnum, []).append(post)\n",
        "\n",
        "    return all_posts"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save Naive QA data without follow ups\n",
        "- class_content_flat.json: the finalized post ```'id', 'subject', 'parent_id', 'tag_good_arr', 'editors', 'anonimity', 'created', 'views', 'thread_id', 'content', 'score', 'type'```\n",
        "- contributions.csv: all edit history of post ```Anonymous\tPost Number\tFolders\tCreated At\tSubmission\tSubmission HTML Removed\tSubject\tPart of Post\tEndorsed by Instructor```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# a csv file of the following columns for each semesters data: {COURSE}_{SEMESTER}_QA_nofollowup.csv\n",
        "# postnum, subject, question, answer, answer_by, folders, views, utc_q, utc_a, numlikes_q, numlikes_a, endorsed_q, endorsed_a\n",
        "def extract_qa(posts):\n",
        "    q_dict, a_dict = {}, {}\n",
        "    for post in posts:\n",
        "        if post['type'] == \"question\": \n",
        "            assert(post['score'] == len(post['tag_good_arr']))\n",
        "            q_dict = {\"id_q\": post['id'], \"subject\": str_html(post['subject']), \n",
        "                      \"question\": post['clean_content'], \n",
        "                      \"html_q\": post['content'], \"folders\": post['folders'], \n",
        "                      \"views\": post['views'], \"utc_q\": post['utc'], \n",
        "                      \"numlikes_q\": post['score'], \"endorsed_q\": post['endorsed']}\n",
        "        \n",
        "        elif post['type'] in [\"i_answer\", \"s_answer\"]:  # a does not have score field\n",
        "            a_dict.update({post['type']: \n",
        "                           {**post['answer_edit'],\n",
        "                            \"id_a\": post['id'],\n",
        "                            \"html_a\": post['content'], \n",
        "                            \"answer_by\": 'student' if post['type'] == 's_answer' else 'instructor',\n",
        "                            \"utc_a\": post['utc'], \n",
        "                            \"numlikes_a\": len(post['tag_good_arr']), \"endorsed_a\": post['endorsed']}})\n",
        "        # else: continue # skip other types like note & followup for now\n",
        "    return q_dict, a_dict\n",
        "\n",
        "def create_qa(semester, all_posts, QAWriter):\n",
        "    qa_count, notes = 0, {}\n",
        "    for postnum, posts in all_posts.items():\n",
        "        q_dict, a_dict = extract_qa(posts)\n",
        "        if len(q_dict) == 0 or len(a_dict) == 0: # print(\"No question or answer found\", posts)\n",
        "            notes[postnum] = posts # add to the notes dict\n",
        "            continue\n",
        "        for a in a_dict.values():\n",
        "            qa_count += 1\n",
        "            QAWriter.writerow({\"semester\": semester, \"postnum\": postnum, **q_dict, **a})\n",
        "    \n",
        "    print(f\"For {semester}, total #posts = {len(all_posts)}, QA pairs without followups = {qa_count}\")\n",
        "    return notes, {\"total_posts\": len(all_posts), \"total_qas\": qa_count}\n",
        "\n",
        "def create_notes(semester, notes, NoteWriter):\n",
        "    notes_count = 0\n",
        "    for postnum, posts in notes.items():\n",
        "        for post in posts:\n",
        "            if post['type'] == 'note':\n",
        "                notes_count += 1\n",
        "                note = post['clean_content']\n",
        "                subject = str_html(post['subject'])\n",
        "                utc = post['utc']\n",
        "                NoteWriter.writerow({\"semester\": semester, 'postnum': postnum, 'id': post['id'], \n",
        "                'subject': subject, 'utc': utc, 'note': note, 'html': post['content']})\n",
        "    \n",
        "    print(f\"#note posts = {notes_count}\")\n",
        "    return {\"total_notes\": notes_count}\n",
        "\n",
        "def get_raw_materials(course, semester):\n",
        "    # PATH = set_paths(course, semester)[1]\n",
        "    print(PATH)\n",
        "    contributions = get_contributions(PATH)\n",
        "    class_content_flat = get_class_content_flat(PATH)\n",
        "    return class_content_flat, contributions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save QA data with following format\n",
        "-  a csv file of the following columns for each semesters data: {COURSE}_{SEMESTER}_QA_nofollowup.csv\n",
        "``` postnum, subject, question, s_answer, i_answer, folders, views, utc_q, utc_a, numlikes_q, numlikes_a, endorsed_q, endorsed_a```\n",
        "\n",
        "## Each piazza post is one row\n",
        "- postnum: can be useful for reference pointing, e.g., \n",
        "  - Check @887 to see if it helps you understand the operations and their order\n",
        "  - You can check the post @118_f1 at lecture 2 thread\n",
        "- question: `updated_question` can be better than `started_off_question`, as we don't clear about changes in question wording for model to learn, only keep `updated_question`\n",
        "- answer: {started_off/updated}_{i/s}_answer\n",
        "  - `X_i_answer` is from `i`nstructor, and `X_s_answer` is from `s`tudent\n",
        "  - `updated_X_answer` can be naively seen as better than `started_off_X_answer` after edit\n",
        "- answer_by: instructor/student\n",
        "- folders: I kept the original folder labels, note that across different semesters, things may be labled slightly different, e.g., `quiz` vs. `quizzes`, `hw1` vs. `hw1p1`, etc. \n",
        "- endorsed: T/F endorsed by instructor\n",
        "- numlikes: tag_good_arr (user_ids), score being #people that liked this post? edited by? viewed by?\n",
        "- followup: a dictionary of threads {\"thread_id\": [\"\", \"\", ], ...}, some info are not saved in this format, e.g., if an instructor endorsed an followup response, etc.\n",
        "- images are labeled with [IMG][prepended link] in text => **TODO OCR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_all_semesters(sem_list, COURSE):\n",
        "    counts = Counter(total_posts=0, total_qas=0, total_notes=0)\n",
        "    all_posts, all_notes = dict(), dict()\n",
        "    with open(f'{BASE}/{COURSE}_QA_nofollowup_preOCR.csv', 'w') as csvfile:\n",
        "        QAWriter = csv.DictWriter(csvfile, fieldnames=['semester', 'postnum', 'subject', 'question', \n",
        "        'started_off_answer', 'updated_answer', 'answer_by', 'folders', 'views', 'html_q', 'html_a',\n",
        "        'id_q', 'id_a', 'utc_q', 'utc_a', 'numlikes_q', 'numlikes_a', 'endorsed_q', 'endorsed_a'])\n",
        "        QAWriter.writeheader()\n",
        "        for semester in sem_list:\n",
        "            print(f\"\\n\\n#### Processing {COURSE} {semester} \\n\")\n",
        "            class_content_flat, contributions = get_raw_materials(COURSE, semester)\n",
        "            # generate QA data & notes (without followups)\n",
        "            post_semester = get_all_posts(class_content_flat, contributions)\n",
        "            notes, update_counts = create_qa(semester, post_semester, QAWriter)\n",
        "            all_notes[semester] = notes\n",
        "            # using a Counter dict to count the number of posts, qas, notes for each semester\n",
        "            counts.update(update_counts)\n",
        "            post_semester = {f\"{semester}_{postnum}\": posts for postnum, posts in post_semester.items()}\n",
        "            all_posts.update(post_semester)\n",
        "\n",
        "    with open(f'{BASE}/{COURSE}_notes_nofollowup_preOCR.csv', 'w') as notecsv:\n",
        "        NoteWriter = csv.DictWriter(notecsv, fieldnames=['semester', 'postnum', 'id', 'subject', 'utc', 'note', 'html'])\n",
        "        NoteWriter.writeheader()\n",
        "        for semester, notes in all_notes.items():\n",
        "            update_counts = create_notes(semester, notes, NoteWriter)\n",
        "            counts.update(update_counts)\n",
        "    \n",
        "    with open(f\"all_posts_semesters.json\", 'w') as f: json.dump(to_json(all_posts), f, indent=4)\n",
        "    print(f\"Out of {len(semesters[COURSE])} semesters of {COURSE}, {counts}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "#### Processing sample_course sample_semester \n",
            "\n",
            "sample_course_data/Piazza_Data/Piazza_sample_semester/\n",
            "sample_course_data/Piazza_Data/Piazza_sample_semester/ contributions.csv 15\n",
            "Folders 3 {'logistics', 'lab5', 'c_project'}\n",
            "class_content_flat.json 11\n",
            "For sample_semester, total #posts = 3, QA pairs without followups = 3\n",
            "#note posts = 0\n",
            "Out of 1 semesters of sample_course, Counter({'total_posts': 3, 'total_qas': 3, 'total_notes': 0})\n",
            "3\n",
            "instructors 3 {'i6q23gcekfm15v', 'gooyf9nn3PO', 'l01f6628pmr4ce'}\n"
          ]
        }
      ],
      "source": [
        "# sem_list = semesters[COURSE]\n",
        "parse_all_semesters([SEMESTER], COURSE)\n",
        "\n",
        "# load all_posts from previous run saved json\n",
        "with open(f\"all_posts_semesters.json\", 'r') as f:\n",
        "    all_posts = json.load(f)\n",
        "print(len(all_posts))\n",
        "\n",
        "# Note that to really loop through all semesters, get_instructors() can't just take the default PATH\n",
        "all_instructors = {SEMESTER: get_instructors()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all_qas 3 Index(['semester', 'postnum', 'subject', 'question', 'started_off_answer',\n",
            "       'updated_answer', 'answer_by', 'folders', 'views', 'html_q', 'html_a',\n",
            "       'id_q', 'id_a', 'utc_q', 'utc_a', 'numlikes_q', 'numlikes_a',\n",
            "       'endorsed_q', 'endorsed_a'],\n",
            "      dtype='object')\n",
            "all_notes 0 Index(['semester', 'postnum', 'id', 'subject', 'utc', 'note', 'html'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "all_qas = pd.read_csv(get_part_csv(COURSE, \"QA\"))\n",
        "all_notes = pd.read_csv(get_part_csv(COURSE, \"notes\"))\n",
        "print(\"all_qas\", len(all_qas), all_qas.columns)\n",
        "print(\"all_notes\", len(all_notes), all_notes.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# process {course}_QA_nofollowup_preOCR.csv's column of html, produce images into folders\n",
        "# process {course}_notes_nofollowup_preOCR.csv's column of html, produce images into folders\n",
        "# eliminate rows with images, produce new csv files \n",
        "\n",
        "def download_images_label_qa(row, course=COURSE):\n",
        "    html_q, html_a = row[\"html_q\"], row[\"html_a\"]\n",
        "    imgs_q = extract_img_from_html(html_q, row[\"id_q\"], \"question\", row[\"postnum\"], row[\"semester\"]) if isinstance(html_q, str) else []\n",
        "    imgs_a = extract_img_from_html(html_a, row[\"id_a\"], \"answer\", row[\"postnum\"], row[\"semester\"]) if isinstance(html_a, str) else []\n",
        "    row[\"num_images\"] = len(imgs_q) + len(imgs_a)\n",
        "    # if row[\"num_images\"] > 0 and ( row[\"semester\"] == 2022 or (row[\"semester\"] == 2021 and row[\"postnum\"] >= 1548) ):\n",
        "    if row[\"num_images\"] > 0: write_to_json(f\"{course}_data/Processed_Data\", \"images.json\", imgs_q + imgs_a)\n",
        "    return row\n",
        "\n",
        "def download_images_label_notes(row, course=COURSE):\n",
        "    html = row[\"html\"]\n",
        "    imgs = extract_img_from_html(html, row[\"id\"], \"note\", row[\"postnum\"], row[\"semester\"]) if isinstance(html, str) else []\n",
        "    row[\"num_images\"] = len(imgs)\n",
        "    if row[\"num_images\"] > 0: write_to_json(f\"{course}_data/Processed_Data\", \"images.json\", imgs)\n",
        "    return row"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Downloading images in posts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>semester</th>\n",
              "      <th>postnum</th>\n",
              "      <th>subject</th>\n",
              "      <th>question</th>\n",
              "      <th>started_off_answer</th>\n",
              "      <th>updated_answer</th>\n",
              "      <th>answer_by</th>\n",
              "      <th>folders</th>\n",
              "      <th>views</th>\n",
              "      <th>html_q</th>\n",
              "      <th>html_a</th>\n",
              "      <th>id_q</th>\n",
              "      <th>id_a</th>\n",
              "      <th>utc_q</th>\n",
              "      <th>utc_a</th>\n",
              "      <th>numlikes_q</th>\n",
              "      <th>numlikes_a</th>\n",
              "      <th>endorsed_q</th>\n",
              "      <th>endorsed_a</th>\n",
              "      <th>num_images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sample_semester</td>\n",
              "      <td>7</td>\n",
              "      <td>coursebook unlock</td>\n",
              "      <td>when i currently try to download the matlab co...</td>\n",
              "      <td>Seems to be unblocked now. Try again?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>instructor</td>\n",
              "      <td>logistics</td>\n",
              "      <td>12</td>\n",
              "      <td>when i currently try to download the matlab co...</td>\n",
              "      <td>Seems to be unblocked now. Try again?</td>\n",
              "      <td>l5lje4qurpswp</td>\n",
              "      <td>l5ljutq8avt6w4</td>\n",
              "      <td>2022-07-14 21:21:59 UTC</td>\n",
              "      <td>2022-07-14 21:34:58 UTC</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sample_semester</td>\n",
              "      <td>486</td>\n",
              "      <td>Lab 5.5</td>\n",
              "      <td>When I am testing I had this error.\\nHow can I...</td>\n",
              "      <td>As KW would say:\\n\\n\"we cannot help you to deb...</td>\n",
              "      <td>As KW would say:\\n\\n\"we cannot help you to deb...</td>\n",
              "      <td>instructor</td>\n",
              "      <td>lab5</td>\n",
              "      <td>281</td>\n",
              "      <td>&lt;p&gt;When I am testing I had this error.&lt;/p&gt;\\n&lt;p...</td>\n",
              "      <td>&lt;p&gt;As KW would say:&lt;/p&gt;\\n&lt;p&gt;&lt;/p&gt;\\n&lt;p&gt;&amp;#34;we c...</td>\n",
              "      <td>l6x5f4tlltb1ey</td>\n",
              "      <td>l6x7po6chew18</td>\n",
              "      <td>2022-08-17 05:03:48 UTC</td>\n",
              "      <td>2022-08-17 06:37:50 UTC</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sample_semester</td>\n",
              "      <td>1477</td>\n",
              "      <td>Can you put an if statement inside another if ...</td>\n",
              "      <td>.</td>\n",
              "      <td>Can you? Yes. Should you? Sometimes. For the p...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>student</td>\n",
              "      <td>c_project</td>\n",
              "      <td>114</td>\n",
              "      <td>&lt;p&gt;.&lt;/p&gt;</td>\n",
              "      <td>&lt;p&gt;Can you? Yes. Should you? Sometimes. For th...</td>\n",
              "      <td>l97k23y4ceh6ck</td>\n",
              "      <td>l97zi81rtwt3fb</td>\n",
              "      <td>2022-10-13 21:10:41 UTC</td>\n",
              "      <td>2022-10-14 04:23:07 UTC</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          semester  postnum  \\\n",
              "0  sample_semester        7   \n",
              "1  sample_semester      486   \n",
              "2  sample_semester     1477   \n",
              "\n",
              "                                             subject  \\\n",
              "0                                  coursebook unlock   \n",
              "1                                            Lab 5.5   \n",
              "2  Can you put an if statement inside another if ...   \n",
              "\n",
              "                                            question  \\\n",
              "0  when i currently try to download the matlab co...   \n",
              "1  When I am testing I had this error.\\nHow can I...   \n",
              "2                                                  .   \n",
              "\n",
              "                                  started_off_answer  \\\n",
              "0              Seems to be unblocked now. Try again?   \n",
              "1  As KW would say:\\n\\n\"we cannot help you to deb...   \n",
              "2  Can you? Yes. Should you? Sometimes. For the p...   \n",
              "\n",
              "                                      updated_answer   answer_by    folders  \\\n",
              "0                                                NaN  instructor  logistics   \n",
              "1  As KW would say:\\n\\n\"we cannot help you to deb...  instructor       lab5   \n",
              "2                                                NaN     student  c_project   \n",
              "\n",
              "   views                                             html_q  \\\n",
              "0     12  when i currently try to download the matlab co...   \n",
              "1    281  <p>When I am testing I had this error.</p>\\n<p...   \n",
              "2    114                                           <p>.</p>   \n",
              "\n",
              "                                              html_a            id_q  \\\n",
              "0              Seems to be unblocked now. Try again?   l5lje4qurpswp   \n",
              "1  <p>As KW would say:</p>\\n<p></p>\\n<p>&#34;we c...  l6x5f4tlltb1ey   \n",
              "2  <p>Can you? Yes. Should you? Sometimes. For th...  l97k23y4ceh6ck   \n",
              "\n",
              "             id_a                    utc_q                    utc_a  \\\n",
              "0  l5ljutq8avt6w4  2022-07-14 21:21:59 UTC  2022-07-14 21:34:58 UTC   \n",
              "1   l6x7po6chew18  2022-08-17 05:03:48 UTC  2022-08-17 06:37:50 UTC   \n",
              "2  l97zi81rtwt3fb  2022-10-13 21:10:41 UTC  2022-10-14 04:23:07 UTC   \n",
              "\n",
              "   numlikes_q  numlikes_a  endorsed_q  endorsed_a  num_images  \n",
              "0           0           2       False        True           0  \n",
              "1           0           0       False       False           1  \n",
              "2           0           0       False       False           0  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_qas = all_qas.apply(lambda row: download_images_label_qa(row), axis=1)\n",
        "all_qas.to_csv(f\"{BASE}/{COURSE}_QA_nofollowup_preOCR_imgtag.csv\", index=False)\n",
        "\n",
        "all_notes = all_notes.apply(lambda row: download_images_label_notes(row), axis=1)\n",
        "# all_notes.to_csv(f\"{BASE}/{COURSE}_notes_nofollowup_preOCR_imgtag.csv\", index=False)\n",
        "all_qas.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Format each QA post into json files with entries\n",
        "```\n",
        "instruction: post['question']\n",
        "input: ''\n",
        "output: post['started_off_answer']\n",
        "text: 'You're a helpful and knowledgeable teaching assistant in CS1. \n",
        "      Answer this question for a novice student. \n",
        "      ### Question: {post['question']} ### Answer: {post['started_off_answer']}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jsonify total #QA 2 in course sample_course\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'id': 0,\n",
              "  'semester': 'sample_semester',\n",
              "  'folder': 'logistics',\n",
              "  'answer_by_instructor': True,\n",
              "  'question': 'coursebook unlock\\nwhen i currently try to download the matlab coursebook, it says the file is locked. could this please be unlocked?',\n",
              "  'answer': 'Seems to be unblocked now. Try again?'},\n",
              " {'id': 1,\n",
              "  'semester': 'sample_semester',\n",
              "  'folder': 'c_project',\n",
              "  'answer_by_instructor': False,\n",
              "  'question': 'Can you put an if statement inside another if statement?\\n.',\n",
              "  'answer': \"Can you? Yes. Should you? Sometimes. For the project, it's perfectly okay.\\n\\nGenerally, it's considered bad practice as:\\n\\n\\nif (A) {\\n\\tif (B) {\\n\\t\\t// Some code\\n\\t}\\n}\\ncan always be written as:\\n\\nif (A && B) {\\n\\t// Some code\\n}\\n\\nBut, there isn't really an actual issue with it outside of readability.\"}]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO: some filtering mechanisms errors/num_imgs to get rid of the ones without proper OCR\n",
        "def non_nan_str(val): return \"\" if isinstance(val, float) else val\n",
        "# use updated if exist and then started_off\n",
        "def final_answer(start, updated): \n",
        "    result = non_nan_str(updated)\n",
        "    if result == \"\": return non_nan_str(start)\n",
        "    else: return result\n",
        "\n",
        "def get_qa_json(posts, course=COURSE):\n",
        "    with open(f\"{BASE}/{course}_QA_simplified_noOCR.json\", 'w') as json_file:\n",
        "        json_list = []\n",
        "        for index, post in posts.iterrows():\n",
        "            if post['num_images'] > 0: continue\n",
        "            subject = post['subject']\n",
        "            question = non_nan_str(post['question'])\n",
        "            instruction = f\"{subject}\\n{question}\"\n",
        "            answer = final_answer(post['started_off_answer'], post['updated_answer'])\n",
        "            # role = 'You are a helpful and knowledgeable teaching assistant in an introductory programming class on Matlab and C. Answer this question for a student.'\n",
        "            # prompt = f\"{role}\\n### Question: {instruction} \\n### Answer: {answer}\"\n",
        "            json_dict = {\n",
        "                \"id\": len(json_list), #not unique: str(post[\"semester\"])+ \"_\" + post[\"id_q\"],\n",
        "                \"semester\": post[\"semester\"],\n",
        "                \"folder\": post[\"folders\"],\n",
        "                \"answer_by_instructor\": post[\"answer_by\"] == \"instructor\",\n",
        "                \"question\": instruction,\n",
        "                \"answer\": answer,\n",
        "            }\n",
        "            json_list.append(json_dict)\n",
        "        json.dump(json_list, json_file, indent=4)\n",
        "        print(\"Jsonify total #QA\", len(json_list), \"in course\", course)\n",
        "    return json_list\n",
        "\n",
        "# if filter out the ones with images or answered by students\n",
        "get_qa_json(all_qas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Index(['semester', 'postnum', 'subject', 'question', 'started_off_answer',\n",
              "       'updated_answer', 'answer_by', 'folders', 'views', 'html_q', 'html_a',\n",
              "       'id_q', 'id_a', 'utc_q', 'utc_a', 'numlikes_q', 'numlikes_a',\n",
              "       'endorsed_q', 'endorsed_a', 'num_images'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# len(all_qas[all_qas[\"num_images\"] == 0])\n",
        "# len(all_qas[all_qas[\"answer_by\"] == \"student\"])\n",
        "print(len(all_qas))\n",
        "all_qas.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare data for RLHF \n",
        "```\n",
        "[{\n",
        "'instruction': student question,\n",
        "'input': '',\n",
        "'output1': started off answer,\n",
        "'output2': final updated answer,\n",
        "'preference': 2\n",
        "}]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jsonify total started & updated answer 1 in course sample_course\n"
          ]
        }
      ],
      "source": [
        "def get_rlanswer_json(posts, course=COURSE):\n",
        "    with open(f\"{BASE}/{course}_RL_answers_id.json\", 'w') as json_file:\n",
        "        json_list = []\n",
        "        for index, post in posts.iterrows():\n",
        "            # uncomment the next line to filter out the posts with images\n",
        "            # if post['num_images'] > 0: continue\n",
        "            subject = post['subject']\n",
        "            question = non_nan_str(post['question'])\n",
        "            instruction = f\"{subject}\\n{question}\"\n",
        "            updated_answer = non_nan_str(post['updated_answer'])\n",
        "            if non_nan_str(updated_answer) == \"\":\n",
        "                continue # skip the ones without updated answer\n",
        "            assert updated_answer != \"\", \"updated_answer is empty\"  \n",
        "            json_dict = {\n",
        "                \"semester\": post[\"semester\"],\n",
        "                \"id_q\": post[\"id_q\"],\n",
        "                \"instruction\": instruction,\n",
        "                \"input\": '',\n",
        "                \"output1\": non_nan_str(post['started_off_answer']),\n",
        "                \"output2\": updated_answer,\n",
        "                \"preference\": 2\n",
        "            }\n",
        "            json_list.append(json_dict)\n",
        "        json.dump(json_list, json_file, indent=4)\n",
        "            \n",
        "    print(\"Jsonify total started & updated answer\", len(json_list), \"in course\", course)\n",
        "    # return json_list\n",
        "\n",
        "# total started & updated answer\n",
        "get_rlanswer_json(all_qas)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Recreate thread & followups from the data\n",
        "- using `class_content_flat.json` fields such as\n",
        "  - 'id': 'l75cspcyk4f1xb',\n",
        "  - 'content': ```<p></p>```,\n",
        "    - look up content from `contributions.csv` -> `Submission` column if there's exact match\n",
        "  - 'created': '2022-08-22T22:52:27.874Z',\n",
        "    - look up content from `contributions.csv` -> `Created At` column if there's exact match (e.g.,'2021-12-14 16:08:43 UTC')\n",
        "  - 'parent_id': 'l7272ltvzwk53o',\n",
        "  - 'thread_id': 'l6zorg9l2ky5mn',\n",
        "\n",
        "### Followups\n",
        "- note that course may have those FAQ note posts that many Q&A will exist in followups\n",
        "- {COURSE}_{SEMESTER}_followups.csv\n",
        "- **TODO**: a possible way to do it is to merge adjacent student posts & instructor posts after sorted by time\n",
        "\n",
        "### Fields:\n",
        "- postnum: \n",
        "- follownum: first sort followup of a note/question and append to postnum like 590_f1, etc.\n",
        "- utc: can be used to sort & merge adjacent posts together\n",
        "- thread_type: note/question [can use postnum to access the corresponding note/qa text]\n",
        "- type: followup/followup_response\n",
        "- by: student/instructor\n",
        "- content: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4 entries, 0 to 3\n",
            "Data columns (total 8 columns):\n",
            " #   Column                            Non-Null Count  Dtype \n",
            "---  ------                            --------------  ----- \n",
            " 0   semester                          4 non-null      object\n",
            " 1   postnum                           4 non-null      object\n",
            " 2   posttype                          4 non-null      object\n",
            " 3   folders                           4 non-null      object\n",
            " 4   type                              4 non-null      object\n",
            " 5   num_followup_and_response         4 non-null      int64 \n",
            " 6   len_followup_and_response_text    4 non-null      int64 \n",
            " 7   num_followup_and_response_images  4 non-null      int64 \n",
            "dtypes: int64(3), object(5)\n",
            "memory usage: 384.0+ bytes\n"
          ]
        }
      ],
      "source": [
        "# make a df from all_posts with columns\n",
        "def get_followups_stats(all_posts, all_instructors):\n",
        "    followups_stats = []\n",
        "    for postid, posts in all_posts.items():\n",
        "        semester, postnum = \"_\".join(postid.split('_')[:-1]), postid.split('_')[-1]\n",
        "        instructors = all_instructors[semester]\n",
        "        num_followup_and_response, len_followup_and_response_text, num_followup_and_response_images, \\\n",
        "        num_by_student, num_by_instructor, len_by_student, len_by_instructor, img_by_student, img_by_instructor = 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
        "        posttype = []\n",
        "        has_followup = False\n",
        "        for post in posts:\n",
        "            folders = post['folders']\n",
        "            if post['type'] in ['followup', 'followup_response']:\n",
        "                has_followup = True\n",
        "                num_followup_and_response += 1\n",
        "                len_post, img_post = len(post['clean_content']), post['content'].count(\"<img\")\n",
        "                len_followup_and_response_text += len_post\n",
        "                num_followup_and_response_images += img_post\n",
        "                if post[\"editors\"][0] in instructors:\n",
        "                    num_by_instructor += 1\n",
        "                    len_by_instructor += len_post\n",
        "                    img_by_instructor += img_post\n",
        "                else: \n",
        "                    num_by_student += 1\n",
        "                    len_by_student += len_post\n",
        "                    img_by_student += img_post\n",
        "            else: posttype.append(post['type'])\n",
        "        if has_followup: \n",
        "            d = {'semester': semester, 'postnum': postnum, 'posttype': posttype, 'folders': folders}\n",
        "            s = {**d, 'type': 'student', 'num_followup_and_response': num_by_student, 'len_followup_and_response_text': len_by_student, 'num_followup_and_response_images': img_by_student}\n",
        "            followups_stats.append(s)\n",
        "            i = {**d, 'type': 'instructor', 'num_followup_and_response': num_by_instructor, 'len_followup_and_response_text': len_by_instructor, 'num_followup_and_response_images': img_by_instructor}\n",
        "            followups_stats.append(i)\n",
        "    return pd.DataFrame(followups_stats)\n",
        "\n",
        "followups_stats = get_followups_stats(all_posts, all_instructors)\n",
        "followups_stats.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>semester</th>\n",
              "      <th>postnum</th>\n",
              "      <th>posttype</th>\n",
              "      <th>folders</th>\n",
              "      <th>type</th>\n",
              "      <th>num_followup_and_response</th>\n",
              "      <th>len_followup_and_response_text</th>\n",
              "      <th>num_followup_and_response_images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sample_semester</td>\n",
              "      <td>7</td>\n",
              "      <td>[question, i_answer]</td>\n",
              "      <td>logistics</td>\n",
              "      <td>student</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sample_semester</td>\n",
              "      <td>7</td>\n",
              "      <td>[question, i_answer]</td>\n",
              "      <td>logistics</td>\n",
              "      <td>instructor</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sample_semester</td>\n",
              "      <td>1477</td>\n",
              "      <td>[question, s_answer]</td>\n",
              "      <td>c_project</td>\n",
              "      <td>student</td>\n",
              "      <td>2</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sample_semester</td>\n",
              "      <td>1477</td>\n",
              "      <td>[question, s_answer]</td>\n",
              "      <td>c_project</td>\n",
              "      <td>instructor</td>\n",
              "      <td>2</td>\n",
              "      <td>585</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          semester postnum              posttype    folders        type  \\\n",
              "0  sample_semester       7  [question, i_answer]  logistics     student   \n",
              "1  sample_semester       7  [question, i_answer]  logistics  instructor   \n",
              "2  sample_semester    1477  [question, s_answer]  c_project     student   \n",
              "3  sample_semester    1477  [question, s_answer]  c_project  instructor   \n",
              "\n",
              "   num_followup_and_response  len_followup_and_response_text  \\\n",
              "0                          0                               0   \n",
              "1                          1                              44   \n",
              "2                          2                              47   \n",
              "3                          2                             585   \n",
              "\n",
              "   num_followup_and_response_images  \n",
              "0                                 0  \n",
              "1                                 0  \n",
              "2                                 0  \n",
              "3                                 0  "
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "followups_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ad-hoc data analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all_qas 3 Index(['semester', 'postnum', 'subject', 'question', 'started_off_answer',\n",
            "       'updated_answer', 'answer_by', 'folders', 'views', 'html_q', 'html_a',\n",
            "       'id_q', 'id_a', 'utc_q', 'utc_a', 'numlikes_q', 'numlikes_a',\n",
            "       'endorsed_q', 'endorsed_a', 'num_images'],\n",
            "      dtype='object')\n",
            "all_notes 0 Index(['semester', 'postnum', 'id', 'subject', 'utc', 'note', 'html'], dtype='object')\n",
            "all_posts <class 'dict'> 3\n"
          ]
        }
      ],
      "source": [
        "print(\"all_qas\", len(all_qas), all_qas.columns)\n",
        "print(\"all_notes\", len(all_notes), all_notes.columns)\n",
        "print(\"all_posts\", type(all_posts), len(all_posts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>endorsed</th>\n",
              "      <th>views</th>\n",
              "      <th>score</th>\n",
              "      <th>postnum</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>semester</th>\n",
              "      <th>folders</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">sample</th>\n",
              "      <th>c_project</th>\n",
              "      <td>0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lab5</th>\n",
              "      <td>0</td>\n",
              "      <td>281.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>logistics</th>\n",
              "      <td>1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    endorsed  views  score  postnum\n",
              "semester folders                                   \n",
              "sample   c_project         0  114.0    0.0        6\n",
              "         lab5              0  281.0    0.0        2\n",
              "         logistics         1   12.0    0.0        3"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_posts_df = pd.DataFrame([{\"semester\": postid.split(\"_\")[0], **post} for postid, posts in all_posts.items() for post in posts])\n",
        "all_posts_df.groupby(['type']).agg({'endorsed': 'sum', 'views': 'sum', 'score': 'sum', 'postnum': 'count'})\n",
        "\n",
        "# split the folders column into multiple rows by \";\"\n",
        "def split_folders(folders):\n",
        "    if isinstance(folders, float) or folders is None: return []\n",
        "    else: return folders.split(\"; \")\n",
        "\n",
        "all_posts_df['folders'] = all_posts_df['folders'].apply(split_folders)\n",
        "all_posts_df = all_posts_df.explode('folders')\n",
        "all_posts_df.groupby(['semester', 'folders']).agg({'endorsed': 'sum', 'views': 'sum', 'score': 'sum', 'postnum': 'count'})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
